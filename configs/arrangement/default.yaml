# Arrangement Generator Configuration
model:
  name: "ArrangementTransformer"
  d_model: 512
  n_heads: 8
  n_layers: 6
  d_ff: 2048
  max_seq_length: 128
  dropout: 0.1
  
  # Coverage penalty settings
  coverage_penalty: 0.3
  max_repeat_length: 4  # Maximum allowed consecutive repetitions
  
  # Style conditioning
  style_embedding_dim: 64
  
  # Section constraints
  min_sections: 3
  max_sections: 8
  section_types: ['INTRO', 'VERSE', 'CHORUS', 'BRIDGE', 'OUTRO']
  
  # Bar count constraints per section
  section_bar_constraints:
    INTRO: [2, 4, 8]
    VERSE: [8, 16, 32]
    CHORUS: [8, 16, 32]
    BRIDGE: [4, 8, 16]
    OUTRO: [2, 4, 8]

data:
  dataset_path: "/data/processed/**/arrangement.json"
  batch_size: 32
  num_workers: 4
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  
  # Data augmentation
  tempo_augment_range: [0.8, 1.2]  # BPM multiplier range
  duration_augment_range: [0.7, 1.3]  # Duration multiplier range

training:
  optimizer: "AdamW"
  learning_rate: 0.0001
  weight_decay: 0.01
  gradient_clip_val: 1.0
  
  # Learning rate scheduling
  scheduler: "CosineAnnealingLR"
  lr_scheduler_params:
    T_max: 100
    eta_min: 0.00001
  
  # Training parameters
  max_epochs: 100
  early_stopping_patience: 10
  early_stopping_monitor: "val_loss"
  
  # Teacher forcing settings
  teacher_forcing_ratio: 0.8
  teacher_forcing_decay: 0.995  # Decay per epoch
  min_teacher_forcing: 0.1

generation:
  # Sampling parameters
  temperature: 0.9
  top_k: 50
  top_p: 0.9
  
  # Beam search parameters
  beam_size: 5
  length_penalty: 1.0
  
  # Generation constraints
  max_generation_length: 64
  eos_token_penalty: 0.1

logging:
  log_level: "INFO"
  wandb_project: "ai-music-arrangement"
  checkpoint_dir: "./checkpoints/arrangement"
  log_every_n_steps: 50
  val_check_interval: 0.25

hardware:
  accelerator: "auto"
  devices: "auto"
  precision: "16-mixed"
  strategy: "auto"